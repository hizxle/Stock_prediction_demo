# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KxiVGiGayr0hhQoKHcxKC9c-qevLiNeM

Подключение Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Импорт библиотек"""

!pip install catboost

!pip install xgboost

import pandas as pd
import numpy as np
from ast import literal_eval
from PIL import Image
import requests
from io import BytesIO
from catboost import CatBoostRegressor
from xgboost import XGBRegressor
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_percentage_error
import chardet
from sklearn.linear_model import LinearRegression
from scipy.stats import uniform, randint
import datetime as dt

df = pd.read_csv('dataframe_no_text.csv')

"""# Разделение на обучающую и тестовую выборку"""

X = df.drop(['close'], axis=1)

y = df['close']

X_tr, X_te, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_tr.drop(['tick', 'datetime'], axis=1)
X_test = X_te.drop(['tick', 'datetime'], axis=1)
X_test.head()

"""# Линейная регрессия"""

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Evaluate the model using mean squared error
mse = mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Mean Absolute Percentage Error: {mape}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R-squared: {r2}")

# Print the coefficients of the model
print("Coefficients:")
print(model.coef_)

# Print the intercept of the model
print("Intercept:", model.intercept_)

import plotly.graph_objects as go
fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_pred), mode='lines'))
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_test), mode='lines'))
fig1.show()

"""# XGBoost Regressor"""

model = XGBRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Evaluate the model using mean squared error
mse = mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Mean Absolute Percentage Error: {mape}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R-squared: {r2}")

import plotly.graph_objects as go
fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_pred), mode='lines'))
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_test), mode='lines'))
fig1.show()

"""# CatBoost Regressor"""

model = CatBoostRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Evaluate the model using mean squared error
mse = mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Mean Absolute Percentage Error: {mape}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R-squared: {r2}")

import plotly.graph_objects as go
fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_pred), mode='lines'))
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_test), mode='lines'))
fig1.show()

"""# Подбор гиперпараметров XGBoost"""

param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 6),
    'learning_rate': uniform(0.01, 0.19),  # Диапазон [0.01, 0.2)
    'subsample': uniform(0.8, 0.2),        # Диапазон [0.8, 1.0)
    'colsample_bytree': uniform(0.8, 0.2)  # Диапазон [0.8, 1.0)
}

# Создание модели
xgb_model = XGBRegressor()

# Создание метрики для кросс-валидации
mape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)

# Настройка RandomizedSearchCV
random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist,
                                   n_iter=50, scoring=mape_scorer, cv=3, verbose=1, n_jobs=-1, random_state=42)

# Обучение модели с подбором гиперпараметров
random_search.fit(X_train, y_train)

# Вывод лучших параметров
print("Лучшие параметры: ", random_search.best_params_)

# Оценка модели на тестовой выборке
best_model = random_search.best_estimator_
y_pred = best_model.predict(X_test)
test_mape = mean_absolute_percentage_error(y_test, y_pred)
print(f"MAPE на тестовой выборке: {test_mape:.4f}")

# Вычисление MAPE с кросс-валидацией на тренировочной выборке
cross_val_mape = cross_val_score(best_model, X_train, y_train, cv=3, scoring=mape_scorer)
print(f"MAPE с кросс-валидацией на тренировочной выборке: {np.mean(cross_val_mape):.4f}")

mse = mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"Mean Absolute Percentage Error: {mape}")
print(f"Root Mean Squared Error: {rmse}")
print(f"R-squared: {r2}")

import plotly.graph_objects as go
fig1 = go.Figure()
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_pred), mode='lines'))
fig1.add_trace(go.Scatter(x=[i for i in range(253)], y=list(y_test), mode='lines'))
fig1.show()